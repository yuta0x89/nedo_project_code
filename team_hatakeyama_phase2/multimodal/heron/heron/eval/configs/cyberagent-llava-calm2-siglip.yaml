wandb:
 log: true
 entity: "vision-language-leaderboard"
 project: "heron-leaderboard"
 run_name: "cyberagent/llava-calm2-siglip"
 launch: false

testmode: false
torch_dtype: "bf16"
api: false
model_artifact: null
processor_artifact: null
tokenizer_artifact: null

model:
 _target_: transformers.LlavaForConditionalGeneration.from_pretrained
 pretrained_model_name_or_path: "cyberagent/llava-calm2-siglip"
 torch_dtype: "bfloat16"

processor:
 _target_: transformers.AutoProcessor.from_pretrained
 pretrained_model_name_or_path: "cyberagent/llava-calm2-siglip"

tokenizer: null

datasets:
 llava_bench_in_the_wild_artifact_path: 'vision-language-leaderboard/heron-leaderboard/llava-bench-in-the-wild:v0'
 llava_bench_in_the_wild_reference_path: 'vision-language-leaderboard/heron-leaderboard/llava-bench-in-the-wild-reference:v0'
 japanese_heron_bench_artifact_path: 'vision-language-leaderboard/heron-leaderboard/japanese-heron-bench:v0'
 japanese_heron_bench_reference_path: 'vision-language-leaderboard/heron-leaderboard/heron-bench-reference:v0'

generation:
 args:
   max_length: 500
   do_sample: true
   temperature: 0.2
   no_repeat_ngram_size: 2