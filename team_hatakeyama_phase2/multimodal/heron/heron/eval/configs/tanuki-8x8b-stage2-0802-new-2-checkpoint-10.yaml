wandb:
  log: True
  entity: "weblab-geniac1"
  project: "heron-leaderboard"
  run_name: 'team-hatakeyama-phase2/tanuki-8x8b_stage2/0802_new_2/checkpoint-10'
  launch: false

# basic information
testmode: false
torch_dtype: "bf16" # {fp16, bf16, fp32}
# if you don't use api, please set "api" as "false"
# if you use api, please select from "openai", "anthoropic", "google", "cohere", "mistral", "amazon_bedrock"
api: false
model_artifact: null
processor_artifact: null
tokenizer_artifact: null

model:
  _target_: null
  pretrained_model_name_or_path: '/storage5/shiraishi/LLaVA-JP/output_llava/checkpoints/tanuki-8x8b_stage2/0802_new_2/checkpoint-10'
  torch_dtype: "bfloat16"
  ignore_mismatched_sizes: true

processor:
  _target_: null
  pretrained_model_name_or_path: null
  
tokenizer:
  _target_: null
  pretrained_model_name_or_path: null

datasets:
  llava_bench_in_the_wild_artifact_path: 'vision-language-leaderboard/heron-leaderboard/llava-bench-in-the-wild:v0'
  llava_bench_in_the_wild_reference_path: 'vision-language-leaderboard/heron-leaderboard/llava-bench-in-the-wild-reference:v0'
  japanese_heron_bench_artifact_path: 'vision-language-leaderboard/heron-leaderboard/japanese-heron-bench:v0'
  japanese_heron_bench_reference_path: 'vision-language-leaderboard/heron-leaderboard/heron-bench-reference:v0'

generation:
  args:
    max_length: 500
    do_sample: true
    temperature: 0.2
    top_p: 1.0
    no_repeat_ngram_size: 3
