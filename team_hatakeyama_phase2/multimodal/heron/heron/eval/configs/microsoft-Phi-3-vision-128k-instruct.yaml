wandb:
 log: true
 entity: "vision-language-leaderboard"
 project: "heron-leaderboard" 
 run_name: "microsoft/Phi-3-vision-128k-instruct"
 launch: false

testmode: false
torch_dtype: "auto"
api: false
model_artifact: null
processor_artifact: null 
tokenizer_artifact: null

model:
 _target_: transformers.AutoModelForCausalLM.from_pretrained
 pretrained_model_name_or_path: "microsoft/Phi-3-vision-128k-instruct"
 device_map: "cuda"
 trust_remote_code: true
 _attn_implementation: "flash_attention_2" 

processor:
 _target_: transformers.AutoProcessor.from_pretrained
 pretrained_model_name_or_path: "microsoft/Phi-3-vision-128k-instruct"
 trust_remote_code: true

tokenizer: null

datasets:
 llava_bench_in_the_wild_artifact_path: 'vision-language-leaderboard/heron-leaderboard/llava-bench-in-the-wild:v0'
 llava_bench_in_the_wild_reference_path: 'vision-language-leaderboard/heron-leaderboard/llava-bench-in-the-wild-reference:v0'
 japanese_heron_bench_artifact_path: 'vision-language-leaderboard/heron-leaderboard/japanese-heron-bench:v0'
 japanese_heron_bench_reference_path: 'vision-language-leaderboard/heron-leaderboard/heron-bench-reference:v0'

generation:
 args:
   max_length: 256
   do_sample: false
   temperature: 0.0
   no_repeat_ngram_size: 2