{
    "base_model": "llama",
    "model_name_or_path": "hatakeyama-llm-team/Tanuki-8B",
    "version": "v1",
    "freeze_backbone": false,
    "tune_mm_mlp_adapter": false,
    "vision_tower": "google/siglip-so400m-patch14-384",
    "mm_vision_select_layer": -2,
    "pretrain_mm_mlp_adapter": "./output_llava/checkpoints/pretrain-llava-jp-Tanuki-8B-vision-cc300k-siglip-so400m-patch14-384/mm_projector.bin",
    "mm_projector_type": "mlp2x_gelu",
    "mm_vision_select_feature": "patch",
    "data_path": "./dataset/jdocqa/jdocqa.json",
    "lazy_preprocess": false,
    "is_multimodal": true,
    "image_folder": "./dataset/jdocqa/images",
    "image_aspect_ratio": "square",
    "optim": "adamw_bnb_8bit",
    "model_max_length": 4096,
    "double_quant": true,
    "quant_type": "nf4",
    "bits": 16,
    "lora_enable": false,
    "group_by_modality_length": true,
    "fp16": false,
    "bf16": true,
    "output_dir": "./output_llava/checkpoints/finetune-llava-jp-Tanuki-8B-vision-cc300k_jdocqa",
    "num_train_epochs": 5,
    "per_device_train_batch_size": 4,
    "per_device_eval_batch_size": 2,
    "gradient_accumulation_steps": 16,
    "evaluation_strategy": "no",
    "save_strategy": "epoch",
    "save_steps": 250,
    "save_total_limit": 100,
    "learning_rate": 0.00002,
    "weight_decay": 0.0,
    "warmup_ratio": 0.03,
    "logging_steps": 10,
    "gradient_checkpointing": true,
    "dataloader_num_workers": 8,
    "lr_scheduler_type": "cosine",
    "use_wandb": true,
    "wandb_project": "llava-jp-stage2",
    "wandb_name": "Tanuki-8B-vision-cc300k_jdocqa"
}
