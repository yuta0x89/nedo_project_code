{
    "base_model": "gpt2",
    "model_name_or_path": "rinna/japanese-gpt2-small",
    "version": "v1",
    "freeze_backbone": false,
    "tune_mm_mlp_adapter": false,
    "vision_tower": "google/siglip-so400m-patch14-384",
    "mm_vision_select_layer": -2,
    "pretrain_mm_mlp_adapter": "./output_llava/checkpoints/pretrain-llava-v1.5-japanese-gpt2-small_test/checkpoint-2000/mm_projector.bin",
    "mm_projector_type": "mlp2x_gelu",
    "mm_vision_select_feature": "patch",
    "data_path": "./dataset/v0/llava_visual_genome_ja.json",
    "lazy_preprocess": false,
    "is_multimodal": true,
    "image_folder": "./dataset/v0/images/stage2",
    "image_aspect_ratio": "square",
    "optim": "adamw_bnb_8bit",
    "model_max_length": 1532,
    "double_quant": true,
    "quant_type": "nf4",
    "bits": 16,
    "lora_enable": false,
    "group_by_modality_length": true,
    "fp16": false,
    "bf16": true,
    "output_dir": "./output_llava/checkpoints/finetune_gpt2_rinna_small-v1-siglip-so400m-patch14-384",
    "num_train_epochs": 1,
    "per_device_train_batch_size": 2,
    "per_device_eval_batch_size": 2,
    "gradient_accumulation_steps": 2,
    "evaluation_strategy": "no",
    "save_strategy": "steps",
    "save_steps": 2000,
    "save_total_limit": 1,
    "learning_rate": 0.00002,
    "weight_decay": 0.0,
    "warmup_ratio": 0.03,
    "logging_steps": 10,
    "gradient_checkpointing": true,
    "dataloader_num_workers": 16,
    "lr_scheduler_type": "cosine",
    "use_wandb": true,
    "wandb_project": "llava-jp-finetune-test",
    "wandb_name": "rinna-small"
}
